{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43b7d466",
   "metadata": {
    "id": "43b7d466"
   },
   "source": [
    "# <center> CS 178: Machine Learning &amp; Data Mining </center>\n",
    "## <center> Homework 5: Due Friday 9 June 2022 (11:59pm) </center>\n",
    "### <center> Version 1.0 (Last Modified: 30 May 2023) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0921f03",
   "metadata": {
    "id": "a0921f03"
   },
   "source": [
    "---\n",
    "## Instructions\n",
    "\n",
    "\n",
    "This homework (and many subsequent ones) will involve data analysis and reporting on methods and results\n",
    "using Python code. You will submit a **single PDF file** that contains everything to Gradescope. This includes any text you wish to include to describe your results, the complete code snippets of how you attempted each problem, any figures that were generated, and scans of any work on paper that you wish to include. It is important that you include enough detail that we know how you solved the problem, since otherwise we will be unable to grade it.\n",
    "\n",
    "\n",
    "Your homeworks will be given to you as Jupyter notebooks containing the problem descriptions and some template code that will help you get started. You are encouraged to use these starter Jupyter notebooks to complete your assignment and to write your report. This will help you not only ensure that all of the code for the solutions is included, but also will provide an easy way to export your results to a PDF file (for example, doing *print preview* and *printing to pdf*). I recommend liberal use of Markdown cells to create headers for each problem and sub-problem, explaining your implementation/answers, and including any mathematical equations. For parts of the homework you do on paper, scan it in such that it is legible (there are a number of free Android/iOS scanning apps, if you do not have access to a scanner), and include it as an image in the Jupyter notebook.\n",
    "\n",
    "If you have any questions/concerns about using Jupyter notebooks, ask us on EdD. If you decide not to use Jupyter notebooks, but go with Microsoft Word or Latex to create your PDF file, make sure that all of the answers can be generated from the code snippets included in the document.\n",
    "\n",
    "### Summary of Assignment: 100 total points\n",
    "- Problem 1: Implementing kMeans (65 points)\n",
    "    - Problem 1.1: compute_membership (10 points)\n",
    "    - Problem 1.2: initialize_clusters (20 points)\n",
    "    - Problem 1.3: update_centroids (20 points)\n",
    "    - Problem 1.4: fit (15 points)\n",
    "- Problem 2: Experimenting with kMeans (30 points)\n",
    "    - Problem 2.1: Varying k (10 points) \n",
    "    - Problem 2.2: Random initialization (10 points)\n",
    "    - Problem 2.3: Kmeans++ initialization (10 points)\n",
    "- Statement of Collaboration (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648cdb14",
   "metadata": {
    "id": "648cdb14"
   },
   "source": [
    "Before we get started, let's import some libraries that you will make use of in this assignment. Make sure that you run the code cell below in order to import these libraries.\n",
    "\n",
    "**Important: In the code block below, we set `seed=1234`. This is to ensure your code has reproducible results and is important for grading. Do not change this. If you are not using the provided Jupyter notebook, make sure to also set the random seed as below.**\n",
    "\n",
    "**Important: Do not change any codes we give you below, except for those waiting for you to complete. This is to ensure your code has reproducible results and is important for grading.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f788ad34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f788ad34",
    "outputId": "e6f1442e-c54d-4eaf-b2e3-90ca864d2d3f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Fix the random seed for reproducibility\n",
    "# !! Important !! : do not change this\n",
    "seed = 1234\n",
    "np.random.seed(seed)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe91f51-c378-4ba5-b70a-54afba522a36",
   "metadata": {},
   "source": [
    "--- \n",
    "## Problem 1\n",
    "\n",
    "In this problem you will implement the k-means clustering algorithm. Below, you are given some starter code which partially implements the class `KMeansClustering`, which defines a k-means clustering model. \n",
    "\n",
    "Let's also load in some data that we will use for the tests in Problem 1. Here, we are using the Iris dataset, where we're only using the first two features. Although you typically would split your data into a training set and a testing set, we won't do that here because we are only using this data to create some tests for your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c8050d-3ff5-49ec-b4ce-d426f8cbdd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "X, y = load_iris(return_X_y = True)\n",
    "# Only use the first two features\n",
    "X = X[:, :2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fd67ff51-2820-4ba9-b320-9ea029bf7a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeansClustering:\n",
    "    \"\"\" A class representing a k-means clustering algorithm.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k, init_strategy, random_state=None):\n",
    "        np.random.seed(random_state) # Sets the random seed of your implementation\n",
    "        self.k = k  # Number of clusters\n",
    "        self.centroids = None  # A numpy array containing the center of each cluster\n",
    "        assert init_strategy in ['random', 'kmeans++'], 'Did not receive a valid initialization strategy.'\n",
    "        self.init_strategy = init_strategy # The strategy that the algorithm will use to initialize centroids\n",
    "        \n",
    "    def compute_memberships(self, X, centroids):\n",
    "        \"\"\" Given a feature matrix X and an array of centroids, \n",
    "            compute the cluster assignment for each datapoint in X.\n",
    "            \n",
    "        X: numpy array of shape (n, d) where n is the number of datapoints and d is the number of features\n",
    "        centroids: numpy array of shape (k, d) where k is the number of clusters and d is the number of features\n",
    "        \n",
    "        Returns:\n",
    "        which_cluster: numpy array of shape (n, ) containing the cluster assignment for each data point in X\n",
    "        squared_distances: numpy array of shape (n, ) containing the squared distance between each data point in X\n",
    "            and the centroid of its corresponding cluster\n",
    "        \"\"\"\n",
    "        squared_distances = []\n",
    "        which_cluster = []\n",
    "        \n",
    "        ### YOUR CODE STARTS HERE ###\n",
    "        for datapoint in X:\n",
    "            distances = []\n",
    "            for centroid in centroids:\n",
    "                centroidDist = 0\n",
    "                for index, feature in enumerate(datapoint):\n",
    "                    centroidDist += (feature - centroid[index])**2 \n",
    "                distances.append(centroidDist)\n",
    "            minDistance = min(distances)\n",
    "            which_cluster.append(distances.index(minDistance)) # need to determine which cluster here\n",
    "            squared_distances.append(minDistance)\n",
    "                \n",
    "        \n",
    "        ### YOUR CODE ENDS HERE ###\n",
    "                  \n",
    "        which_cluster = np.asarray(which_cluster)\n",
    "        squared_distances = np.asarray(squared_distances)\n",
    "        return which_cluster, squared_distances\n",
    "        \n",
    "    def initialize_clusters(self, X):\n",
    "        \"\"\" Computes the initial clusters based on a feature matrix X.\n",
    "        \n",
    "        X: numpy array of shape (n, d) where n is the number of datapoints and d is the number of features\n",
    "        \n",
    "        Returns:\n",
    "        centroids: numpy array of shape (k, d) where k is the number of clusters and d is the number of features,\n",
    "            corresponding to the initial clusters chosen by the appropriate strategy\n",
    "        \"\"\"\n",
    "        if self.init_strategy == 'random':\n",
    "            \n",
    "            rows = np.random.choice(X.shape[0], replace=False, size = self.k) # TODO : randomly select k rows\n",
    "            centroids = X[rows] # TODO : get the randomly selected rows from X\n",
    "            \n",
    "            centroids = np.asarray(centroids) # Cast to numpy array\n",
    "            return centroids\n",
    "        \n",
    "        elif self.init_strategy == 'kmeans++':\n",
    "            n_rows = X.shape[0]\n",
    "            centroids = []\n",
    "                \n",
    "            first_idx = np.random.choice(n_rows) #TODO : randomly select index of first centroid\n",
    "            first_centroid = X[first_idx]# TODO : get corresponding row from X\n",
    "            \n",
    "            centroids.append(first_centroid)\n",
    "                        \n",
    "            for i in range(self.k - 1):\n",
    "                # Get distance^2 from each datapoint to nearest centroid \n",
    "                # _, squared_distances = # TODO\n",
    "                # use compute_memberships to get nearest centroid and distances\n",
    "                nearestCentroid, squaredDistances = self.compute_memberships(X, centroids)\n",
    "                squaredDistSum = sum(squaredDistances)\n",
    "                for j in range(len(squaredDistances)):\n",
    "                    squaredDistances[j] /= squaredDistSum # normalize it \n",
    "                newCentroid = np.random.choice(n_rows, p=squaredDistances)\n",
    "                centroids.append(X[newCentroid])\n",
    "                # Turn into probability distrubtion\n",
    "                # probs = 0 # TODO\n",
    "                # Sample a new centroid\n",
    "                #row = np.random.choice() # TODO : randomly sample a row according to probs\n",
    "                #centroid = [] # TODO : get corresponding row from X\n",
    "                #centroids.append(centroid)\n",
    "                    \n",
    "            centroids = np.asarray(centroids) # Cast to numpy array\n",
    "            return centroids\n",
    "    \n",
    "    def update_centroids(self, X, which_cluster):\n",
    "        \"\"\" Updates the centroid locations based on a feature matrix X and cluster assignments which_cluster.\n",
    "        \n",
    "        X: numpy array of shape (n, d) where n is the number of datapoints and d is the number of features\n",
    "        which_cluster: numpy array of shape (n, ) where n is the number of datapoints,\n",
    "            corresponding to the cluster assignments of the datapoints in X\n",
    "            \n",
    "        Returns:\n",
    "        centroids: numpy array of shape (k, d) where k is the number of clusters and d is the number of features,\n",
    "            where each centroid corresponds to the mean of the feature vectors in the corresponding cluster.\n",
    "        \"\"\"\n",
    "       \n",
    "        ### YOUR CODE STARTS HERE ###\n",
    "        # which_cluster stores assignments of points' clusters\n",
    "        centroids = []\n",
    "        for i in range(self.k):\n",
    "            selectedRows = []\n",
    "            for value, index in enumerate(which_cluster):\n",
    "                if i == value:\n",
    "                    selectedRows.append(index)\n",
    "            clusterMean = np.mean(X[selectedRows], axis=0) # the mean of the datapoints assigned to the cluster\n",
    "            print(clusterMean)\n",
    "            centroids.append(clusterMean)\n",
    "        \n",
    "        ### YOUR CODE ENDS HERE ###\n",
    "        return centroids\n",
    "        \n",
    "    def fit(self, X, max_iter=100):\n",
    "        \"\"\" Fits the k-means clustering algorithm.\n",
    "        \n",
    "        X: numpy array of shape (n, d) where n is the number of datapoints and d is the number of features,\n",
    "            corresponding to our training data.\n",
    "        \"\"\"\n",
    "        centroids = []  # TODO : initialize centroids\n",
    "        # which_cluster, _ = # TODO : get initial cluster assignments\n",
    "                \n",
    "        converged = False\n",
    "        i = 0  # Iteration counter\n",
    "        while not converged:\n",
    "            new_centroids = [] # TODO : update centroids\n",
    "           # new_which_cluster, _ = # TODO : get new cluster assignments\n",
    "            \n",
    "            # We have reached convergence if the cluster assignments don't change,\n",
    "            # or if we reach the maximum number of iterations.\n",
    "            if np.array_equal(which_cluster, new_which_cluster):\n",
    "                converged = True\n",
    "            elif i == max_iter:\n",
    "                converged = True\n",
    "                \n",
    "            centroids = new_centroids\n",
    "            which_cluster = new_which_cluster\n",
    "            i += 1\n",
    "            \n",
    "        self.centroids = centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe12b2e9-0f34-4514-b7d1-80e0ca141424",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Problem 1.1 (10 points):\n",
    "\n",
    "- Complete the function `compute_memberships`. This function should take in a feature matrix `X` and a numpy array `centroids` containing `k` centroids, i.e. the centers of our clusters. The function should return two things: (1) a numpy array containing the index of which centroid is closest to each datapoint in `X`, and (2) a numpy array containing the squared Euclidean distance to the nearest centroid for each point in `X`.\n",
    "- Run the code block given below to test your implementation. If your code is correct, all tests should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "166deaa2-43a9-42a1-831c-6d8cad5a3c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1a passed: True\n",
      "Test 1b passed: True\n",
      "Test 2a passed: True\n",
      "Test 2b passed: True\n"
     ]
    }
   ],
   "source": [
    "# Use this code block to test your implementation in Problem 1.1\n",
    "# Don't change anything here -- just run it\n",
    "\n",
    "kmeans = KMeansClustering(3, 'random', random_state=seed)\n",
    "c = np.array([[4.5, 3.0], [5.5, 4.0]])\n",
    "which_cluster, squared_distances = kmeans.compute_memberships(X[:5], c)\n",
    "expected_centroid = np.array([1, 0, 0, 0, 1])\n",
    "expected_sq_dist = np.array([0.41, 0.16, 0.08, 0.02, 0.41])\n",
    "print(f'Test 1a passed: {np.array_equal(which_cluster, expected_centroid)}')\n",
    "print(f'Test 1b passed: {np.allclose(squared_distances, expected_sq_dist, rtol=1e-4, atol=1e-4)}')\n",
    "\n",
    "kmeans = KMeansClustering(3, 'random', random_state=seed)\n",
    "c = np.array([[1.0, 10.0], [5.5, 4.0]])\n",
    "which_cluster, squared_distances = kmeans.compute_memberships(X[:5], c)\n",
    "expected_centroid = np.array([1, 1, 1, 1, 1])\n",
    "expected_sq_dist = np.array([0.41, 1.36, 1.28, 1.62, 0.41])\n",
    "print(f'Test 2a passed: {np.array_equal(which_cluster, expected_centroid)}')\n",
    "print(f'Test 2b passed: {np.allclose(squared_distances, expected_sq_dist, rtol=1e-4, atol=1e-4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936e0d7b-923e-4d27-b96e-d42b4fbd95a0",
   "metadata": {},
   "source": [
    "### Problem 1.2 (20 points):\n",
    "\n",
    "- Complete the function `initialize_clusters`. This function takes in a feature matrix `X` and returns a numpy array containing `k` initial centroids. You will implement two different strategies for initialization. Since this initialization is random, it is important that you closely follow the template code given above for this problem in order to make the tests pass.\n",
    "- The first strategy is called `random`, where you will randomly choose `k` data points from the feature matrix `X`. Be careful not to choose the same datapoint twice! Hint: you may find the function `np.random.choice` helpful.\n",
    "- The second strategy is called `kmeans++`. This strategy typically results in better clusters than the `random` strategy. In some more detail, `kmeans++` works as follows:\n",
    "    1. Choose the first centroid as a random datapoint from your feature matrix $X$.\n",
    "    2. For the remaining initial centroids $i = 2, 3, \\dots, k$:\n",
    "        1. For every datapoint $x$ in $X$, compute the squared Euclidean distance from $x$ to the nearest centroid that has already been initialized. This gives you a vector $D$ containing these squared distances.\n",
    "        2. Compute a probability vector by normalizing $D$, i.e. divide each entry in $D$ by the sum total of all the entries in $D$. Call this probability vector $P$.\n",
    "        3. Randomly choose your new initial centroid by sampling from $X$, where we select the $j$th datapoint from $X$ with probability $P[j]$. The function `np.random.choice` has an argument `p` that will assist you with this.\n",
    "\n",
    "\n",
    "- Run the code block given below to test your implementation. If your code is correct, all tests should pass.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "009178b6-e302-4e8d-bf5e-2d6ac967c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 passed: True\n",
      "Test 2 passed: True\n"
     ]
    }
   ],
   "source": [
    "# Use this code block to test your implementation in Problem 1.2\n",
    "# Don't change anything here -- just run it\n",
    "\n",
    "kmeans = KMeansClustering(5, 'random', random_state=seed)\n",
    "init_centroids = kmeans.initialize_clusters(X)\n",
    "expected = np.array([[6.1, 3.], [6.1, 2.9], [6.3, 2.9], [4.6, 3.4], [5.2, 2.7]])\n",
    "print(f'Test 1 passed: {np.array_equal(expected, init_centroids)}')\n",
    "\n",
    "kmeans = KMeansClustering(5, 'kmeans++', random_state=seed)\n",
    "init_centroids = kmeans.initialize_clusters(X)\n",
    "expected = np.array([[4.6, 3.2], [7.2, 3.6], [6.3, 2.7], [5.8, 2.7], [6.7, 2.5]])\n",
    "print(f'Test 2 passed: {np.array_equal(expected, init_centroids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0557e-f7dc-42f1-8706-dcc67aa2a577",
   "metadata": {},
   "source": [
    "### Problem 1.3 (20 points):\n",
    "\n",
    "- Complete the function `update_centroids`. This function takes in a feature matrix `X` and a numpy array `which_cluster` that contains the cluster assignment for each data point in `X`. Note that, in the lecture, we used $Z$ to denote the cluster assignments, i.e. `which_cluster`. The function should return a new numpy array consisting of `k` centroids, where the `i`th returned centroid is the centroid of all datapoints assigned to cluster `i` by `which_cluster`. In this assigment, the clusters are zero-indexed, i.e. if $k=2$ then your cluster assignments should take values `0` or `1`. \n",
    "- Run the code block given below to test your implementation. If your code is correct, all tests should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9829a7c4-3a29-455f-a595-de89d6d364ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 passed: False\n",
      "Test 2 passed: False\n"
     ]
    }
   ],
   "source": [
    "# Use this code block to test your implementation in Problem 1.3\n",
    "# Don't change anything here -- just run it\n",
    "\n",
    "kmeans = KMeansClustering(2, 'random', random_state=seed)\n",
    "which_cluster = np.array([1, 0, 0, 1, 0])\n",
    "centroids = kmeans.update_centroids(X[:5], which_cluster)\n",
    "expected_centroids = np.array([[4.87, 3.27], [4.85, 3.3]])\n",
    "print(f'Test 1 passed: {np.allclose(centroids, expected_centroids, rtol=1e-3, atol=1e-3)}')\n",
    "\n",
    "kmeans = KMeansClustering(3, 'random', random_state=seed)\n",
    "which_cluster = np.array([1, 2, 0, 1, 2])\n",
    "centroids = kmeans.update_centroids(X[:5], which_cluster)\n",
    "expected_centroids = np.array([[4.7, 3.2], [4.85, 3.3], [4.95, 3.3]])\n",
    "print(f'Test 2 passed: {np.allclose(centroids, expected_centroids, rtol=1e-3, atol=1e-3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0815eae8-cc8d-4055-8779-5944e60e9f5b",
   "metadata": {},
   "source": [
    "### Problem 1.4 (15 points):\n",
    "\n",
    "- Complete the function `fit`. This function takes in a feature matrix `X` and runs the k-means clustering algorithm in order to fit `k` centroids to the data. Most of this is already implemented for you, and you only need to finish the lines marked `#TODO`.\n",
    "- Run the code block given below to test your implementation. If your code is correct, all tests should pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dce03c24-e7f5-422b-a8d6-187c8010ec85",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'which_cluster' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Use this code block to test your implementation in Problem 1.4\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Don't change anything here -- just run it\u001b[39;00m\n\u001b[0;32m      4\u001b[0m kmeans \u001b[38;5;241m=\u001b[39m KMeansClustering(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mseed)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mkmeans\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m expected \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m5.15\u001b[39m, \u001b[38;5;241m3.1689\u001b[39m], [\u001b[38;5;241m6.5184\u001b[39m, \u001b[38;5;241m2.94868\u001b[39m]])\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest 1 passed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mallclose(kmeans\u001b[38;5;241m.\u001b[39mcentroids,\u001b[38;5;250m \u001b[39mexpected,\u001b[38;5;250m \u001b[39mrtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m,\u001b[38;5;250m \u001b[39matol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 136\u001b[0m, in \u001b[0;36mKMeansClustering.fit\u001b[1;34m(self, X, max_iter)\u001b[0m\n\u001b[0;32m    131\u001b[0m  new_centroids \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m# TODO : update centroids\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# new_which_cluster, _ = # TODO : get new cluster assignments\u001b[39;00m\n\u001b[0;32m    133\u001b[0m  \n\u001b[0;32m    134\u001b[0m  \u001b[38;5;66;03m# We have reached convergence if the cluster assignments don't change,\u001b[39;00m\n\u001b[0;32m    135\u001b[0m  \u001b[38;5;66;03m# or if we reach the maximum number of iterations.\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m  \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(\u001b[43mwhich_cluster\u001b[49m, new_which_cluster):\n\u001b[0;32m    137\u001b[0m      converged \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    138\u001b[0m  \u001b[38;5;28;01melif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m max_iter:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'which_cluster' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Use this code block to test your implementation in Problem 1.4\n",
    "# Don't change anything here -- just run it\n",
    "\n",
    "kmeans = KMeansClustering(2, 'random', random_state=seed)\n",
    "kmeans.fit(X)\n",
    "expected = np.array([[5.15, 3.1689], [6.5184, 2.94868]])\n",
    "print(f'Test 1 passed: {np.allclose(kmeans.centroids, expected, rtol=1e-3, atol=1e-3)}')\n",
    "\n",
    "kmeans = KMeansClustering(5, 'random', random_state=seed)\n",
    "kmeans.fit(X)\n",
    "expected = np.array([[5.3706, 3.8], [6.11346, 2.8673], [7.05, 3.0833], [4.828125, 3.265625], [5.33158, 2.52105]])\n",
    "print(f'Test 2 passed: {np.allclose(kmeans.centroids, expected, rtol=1e-3, atol=1e-3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245aa031-260a-4f58-bc7e-da2050915afa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem 2: Experiments\n",
    "\n",
    "Now that you've implemented the k-means clustering algorithm, you will experiment with your implementation on a toy dataset. The function `sample_data` below will generate some synthetic (i.e. made-up) data for you to experiment with. In addition, you are provided with a function `plot_decision_boundary`. This function takes in a *trained* `KMeansClassifier` object and a dataset `X`, and plots the resulting decision boundaries.\n",
    "\n",
    "Before starting this problem, you should make sure to read and understand these two functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07721760-1fdc-4324-9c86-bc8d7d3d04ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(n_clusters, n_samples_per_cluster=100, random_state=None):\n",
    "    \"\"\" Samples a synthetic dataset with n_clusters.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    dtheta = 2*np.pi/n_clusters\n",
    "        \n",
    "    samples_all = []\n",
    "    r = 1.  # Radius from origin\n",
    "    sigma = 0.1  # Standard deviation of each cluster\n",
    "    for n in range(n_clusters):\n",
    "        # Polar coordinates: computing the center of each cluster\n",
    "        theta = n * dtheta\n",
    "        x = r * np.cos(theta)\n",
    "        y = r * np.sin(theta)\n",
    "        # Generate samples in each cluster\n",
    "        samples = np.random.randn(n_samples_per_cluster, 2)\n",
    "        samples = sigma * samples + np.array([x,y])\n",
    "        samples_all.append(samples)\n",
    "        \n",
    "    samples_all = np.asarray(samples_all).reshape(-1, 2)\n",
    "    return samples_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c789fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(kmeans, X):\n",
    "    \"\"\" Plots the decision boundary for a KMeansClassifier object that was trained on a dataset X.\n",
    "    \"\"\"\n",
    "    # Create an sklearn KMeans object \n",
    "    sklearn_kmeans = KMeans(n_clusters=kmeans.k)\n",
    "    # We aren't actually using the results of this fit method -- just initializing it\n",
    "    sklearn_kmeans.fit(X)\n",
    "    # Set the sklearn_kmeans centroids to those found by your implementation\n",
    "    sklearn_kmeans.cluster_centers_ = kmeans.centroids\n",
    "    # Plot the decision boundary\n",
    "    decision_boundary = DecisionBoundaryDisplay.from_estimator(sklearn_kmeans, X, \n",
    "                                                               alpha=0.4, grid_resolution=250)\n",
    "    # Plot the training data\n",
    "    decision_boundary.ax_.scatter(*X.T, edgecolor='k', marker='o', label='data')\n",
    "    # Plot the clusters\n",
    "    decision_boundary.ax_.scatter(*kmeans.centroids.T, label='centroids',\n",
    "                                  edgecolor='k', color='red', marker='x', s=64)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92c7bba",
   "metadata": {},
   "source": [
    "In this next line, we'll create a dataset with 6 distinct clusters. Note that we set `random_state=seed` for reproducibility. Be sure to run this line of code in order to create our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dd75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_data(6, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b685691",
   "metadata": {},
   "source": [
    "### Problem 2.1 (10 points):\n",
    "\n",
    "- Fit a `KMeansClustering` object on `X` for every value of `k = [2, 4, 6, 8]`. Use the initialization strategy `random` and make sure to set `random_state=seed` in `KMeansClustering`.\n",
    "- For each of these values of `k`, plot the resulting decision boundary using the provided function `plot_decision_boundary`.\n",
    "- Include a short description (1-2 sentences) of what you see happen as you increase `k`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36333d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aac0c69",
   "metadata": {},
   "source": [
    "### Problem 2.2 (10 points):\n",
    "\n",
    "In your implementation of `KMeansClustering`, you implemented two initialization strategies: random and k-means++. In this problem, you will see the effect that the initialization strategy can have on the resulting clusters. You will fit several `KMeansClustering` objects, each having the same number of clusters, but a different random seed -- thus, you will be simulating several initializations, and seeing their effect on the clusters.\n",
    "\n",
    "- Fit a `KMeansClustering` object on `X` with 6 clusters for each fo the following values of `random_state = [5, 6, 7, 8]`. Use the initialization strategy `random`.\n",
    "- For each of these random initializations, plot the resulting decision boundary using the provided function `plot_decision_boundary`.\n",
    "- Include a short description (1-2 sentences) of what you see happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ad8bab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79414589",
   "metadata": {},
   "source": [
    "### Problem 2.3 (10 points):\n",
    "\n",
    "You will now do the same thing as in Problem 2.2, but with the k-means++ initialization strategy.\n",
    "\n",
    "- Fit a `KMeansClustering` object on `X` with 6 clusters for each fo the following values of `random_state = [5, 6, 7, 8]`. Use the initialization strategy `kmeans++`.\n",
    "- For each of these random initializations, plot the resulting decision boundary using the provided function `plot_decision_boundary`.\n",
    "- Include a short description (1-2 sentences) of what you see happen. Be sure to compare your results with the initialization strategy `random` to your results with the initialization strategy `kmeans++`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde6882a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a052765",
   "metadata": {
    "id": "4a052765"
   },
   "source": [
    "---\n",
    "### Statement of Collaboration (5 points)\n",
    "\n",
    "It is **mandatory** to include a Statement of Collaboration in each submission, with respect to the guidelines below. Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed. If you did not collaborate with anyone, you should write something like \"I completed this assignment without any collaboration.\"\n",
    "\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments, in particular, I encourage the students to organize (perhaps using EdD) to\n",
    "discuss the task descriptions, requirements, bugs in my code, and the relevant technical content before they start\n",
    "working on it. However, you should not discuss the specific solutions, and, as a guiding principle, you are not\n",
    "allowed to take anything written or drawn away from these discussions (i.e. no photographs of the blackboard,\n",
    "written notes, referring to EdD, etc.). Especially after you have started working on the assignment, try\n",
    "to restrict the discussion to EdD as much as possible, so that there is no doubt as to the extent of your\n",
    "collaboration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9e61bd-de24-4115-84a9-1d93a8aa7f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
