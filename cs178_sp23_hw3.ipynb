{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4102902d",
   "metadata": {
    "id": "43b7d466"
   },
   "source": [
    "# <center> CS 178: Machine Learning &amp; Data Mining </center>\n",
    "## <center> Homework 3: Due Friday 12 May 2023 (11:59pm) </center>\n",
    "### <center> Version 1.0 (Last Modified: 1 May 2023) </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c83cc10",
   "metadata": {
    "id": "a0921f03"
   },
   "source": [
    "---\n",
    "## Instructions\n",
    "\n",
    "\n",
    "This homework (and many subsequent ones) will involve data analysis and reporting on methods and results\n",
    "using Python code. You will submit a **single PDF file** that contains everything to Gradescope. This includes any text you wish to include to describe your results, the complete code snippets of how you attempted each problem, any figures that were generated, and scans of any work on paper that you wish to include. It is important that you include enough detail that we know how you solved the problem, since otherwise we will be unable to grade it.\n",
    "\n",
    "\n",
    "Your homeworks will be given to you as Jupyter notebooks containing the problem descriptions and some template code that will help you get started. You are encouraged to use these starter Jupyter notebooks to complete your assignment and to write your report. This will help you not only ensure that all of the code for the solutions is included, but also will provide an easy way to export your results to a PDF file (for example, doing *print preview* and *printing to pdf*). I recommend liberal use of Markdown cells to create headers for each problem and sub-problem, explaining your implementation/answers, and including any mathematical equations. For parts of the homework you do on paper, scan it in such that it is legible (there are a number of free Android/iOS scanning apps, if you do not have access to a scanner), and include it as an image in the Jupyter notebook.\n",
    "\n",
    "If you have any questions/concerns about using Jupyter notebooks, ask us on EdD. If you decide not to use Jupyter notebooks, but go with Microsoft Word or Latex to create your PDF file, make sure that all of the answers can be generated from the code snippets included in the document.\n",
    "\n",
    "### Summary of Assignment: 100 total points\n",
    "- Problem 1: A Small Neural Network (30 points)\n",
    "    - Problem 1.1: Forward Pass (10 points)\n",
    "    - Problem 1.2: Evaluate Loss (10 points)\n",
    "    - Problem 1.3: Network Size (10 points)\n",
    "- Problem 2: Neural Networks in Code (65 points)\n",
    "    - Problem 2.1: Setting up Data (5 points)\n",
    "    - Problem 2.2: Vary Amount of Data (20 points)\n",
    "    - Problem 2.3: Learning Curves (10 points)\n",
    "    - Problem 2.3: Tuning your Neural Network (30 points)\n",
    "- Statement of Collaboration (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f66ea38",
   "metadata": {
    "id": "648cdb14"
   },
   "source": [
    "Before we get started, let's import some libraries that you will make use of in this assignment. Make sure that you run the code cell below in order to import these libraries.\n",
    "\n",
    "**Important: In the code block below, we set `seed=1234`. This is to ensure your code has reproducible results and is important for grading. Do not change this. If you are not using the provided Jupyter notebook, make sure to also set the random seed as below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2775b3ce",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f788ad34",
    "outputId": "e6f1442e-c54d-4eaf-b2e3-90ca864d2d3f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Fix the random seed for reproducibility\n",
    "# !! Important !! : do not change this\n",
    "seed = 1234\n",
    "np.random.seed(seed)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14199026",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1: A Small Neural Network\n",
    "\n",
    "\n",
    "Consider the small neural network given in the image below, which will classify a 3-dimensional feature vector $\\mathbf{x}$ into one of three classes ($y = 0, 1, 2$). You are given an input to this network $\\mathbf{x}$, as well as weights $W$ for the hidden layer and weights $B$ for the output layer. For example, $w_{12}$ is the weight connecting input $x_1$ to hidden unit $h_2$. This network uses the ReLU activation function for the hidden layer, and uses the softmax activation function for the output layer. \n",
    "\n",
    "<img src=\"./hw3_nn_v2.png\" width=500 height=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163fc42a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 3 \\\\ -2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "W = \\begin{bmatrix} \n",
    "    w_{01} & w_{11} & w_{21} & w_{31} \\\\ \n",
    "    w_{02} & w_{12} & w_{22} & w_{32} \\\\\n",
    "    \\end{bmatrix} =\n",
    "    \\begin{bmatrix} \n",
    "    1 & -1 & 0 & 6 \\\\ \n",
    "    2 & 1 & 1 & 3 \\\\\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "B = \\begin{bmatrix} \n",
    "    \\beta_{01} & \\beta_{11} & \\beta_{21} \\\\\n",
    "    \\beta_{02} & \\beta_{12} & \\beta_{22} \\\\\n",
    "    \\beta_{03} & \\beta_{13} & \\beta_{23} \\\\\n",
    "    \\end{bmatrix} =\n",
    "    \\begin{bmatrix}\n",
    "    6 & -1 & 0 \\\\\n",
    "    5 & 0 & 2 \\\\\n",
    "    2 & 1 & 1\n",
    "    \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8da35e",
   "metadata": {},
   "source": [
    "### Problem 1.1 (10 points): Forward Pass\n",
    "- Given the inputs and weights above, compute the values of the hidden units $h_1, h_2$ and the outputs $f_1, f_2, f_3$. You should do this by hand, i.e. you should not write any code to do the calculation, but feel free to use a calculator to help you do the computations.\n",
    "    - You can optionally use $\\LaTeX$ in your answer on the Jupyter notebook. Otherwise, write your answer on paper and include a picture of your answer in this notebook. In order to include an image in Jupyter notebook, save the image in the same directory as the .ipynb file and then write `![caption](image.png)`. Alternatively, you may go to Edit --> Insert Image at the top menu to insert an image into a Markdown cell. **Double check that your image is visible in your PDF submission.**\n",
    "- What class would the network predict for the input $\\mathbf{x}$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3c01b1",
   "metadata": {},
   "source": [
    "<font color = blue> In this cell, I will write down the calculations for computing the values specified in the problem. The formulas needed for this problem can be found in the lecture slides (specifically 1st day of neural networks). \n",
    "    \n",
    "<font color = blue> We add the (bias * weight) with the sum of the inputs times their respective weights, and then apply our activation function, ReLu, to it.\n",
    "    \n",
    "<font color = blue> $h_1 = ReLu( (1*1) + (-1*1) + (0*3) + (6*-2) ) = ReLu(-12) = 0$\n",
    "    \n",
    "<font color = blue> $h_2 = ReLu( (2*1) + (1*1) + (1*3) + (3*-2) ) = ReLu(0) = 0$\n",
    "\n",
    "<font color = blue> Below are the outputs before applying softmax\n",
    "    \n",
    "<font color = blue> $f_1 = (6*1) + (-1*0) + (0*0) = 6$\n",
    "    \n",
    "<font color = blue> $f_2 = (5*1) + (0*0) + (2*0) = 5$\n",
    "    \n",
    "<font color = blue> $f_3 = (2*1) + (1*0) + (1*0) = 2$\n",
    "\n",
    "<font color = blue> Below are the outputs after applying softmax\n",
    "    \n",
    "<font color = blue> $e^{f} = [403.43, 148.41, 7.39] $    \n",
    "\n",
    "<font color = blue> Sum of transformed classes = $559.23$\n",
    "    \n",
    "<font color = blue> $f_1 = \\frac{403.43}{559.23} = 0.72$\n",
    "    \n",
    "<font color = blue> $f_2 = \\frac{148.41}{559.23} = 0.27$\n",
    "    \n",
    "<font color = blue> $f_3 = \\frac{7.39}{559.23} = 0.01$\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a4656f",
   "metadata": {},
   "source": [
    "### Problem 1.2 (10 points): Evaluate Loss\n",
    "Typically when we train neural networks for classification, we seek to minimize the log-loss function. Note that the output of the log-loss function is always greater than zero, but can be arbitrarily large (you should pause for a second and make sure you understand why this is true).\n",
    "\n",
    "- Suppose the true label for the input $\\mathbf{x}$ is $y = 1$. What would be the value of our loss function based on the network's prediction for $\\mathbf{x}$?\n",
    "- Suppose instead that the true label for the input $\\mathbf{x}$ is $y = 2$. What would be the value of our loss function based on the network's prediction for $\\mathbf{x}$?\n",
    "\n",
    "You are free to use numpy / Python to help you calculate this, but don't use any neural network libraries that will automatically calculate the loss for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115bc3db",
   "metadata": {},
   "source": [
    "<font color = blue> To calculate loss below, I will use the log-loss function from the lectures\n",
    "    \n",
    "<font color = blue> if the true label for the input x is y = 1, then the value of our loss function is $-\\log(0.27) = 1.89$\n",
    "    \n",
    "<font color = blue> if the true label for the input x is y = 2, then the value of our loss function is $-\\log(0.01) = 6.64$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c09a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdef308a",
   "metadata": {},
   "source": [
    "### Problem 1.3 (10 points): Network Size\n",
    "- Suppose we change our network so that there are $12$ hidden units instead of $2$. How many total weights and biases would there be in our new network?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd7902",
   "metadata": {},
   "source": [
    "<font color = blue> If we have 12 hidden units, then there would be a total of 4 * 12 = 48 total weights in our new network. This is computed by multiplying number of inputs with the number of hidden units.\n",
    "    \n",
    "<font color = blue> To compute total biases, we multiply the # of hidden units + 1 (include the bias) with the number of output classes. This is 13 * 3 = 39 total biases in our new network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0749e7",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2: Neural Networks in Code\n",
    "\n",
    "In the second problem of this assignment, you will get some hands-on experience working with neural networks. We will be using the scikit-learn implementation of a multi-layer perceptron (MLP). See [here](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) for the corresponding documentation. Although there are specialized Python libraries for neural networks, like [TensorFlow](https://www.tensorflow.org/) and [PyTorch](https://pytorch.org/), we'll stick with scikit-learn as you're already familiar with this library.\n",
    "\n",
    "In this problem, we'll be working with the MNIST dataset, which we already saw in Homework 1. As a reminder, this is an image classification dataset, where each image is a hand-written digit. Take a look at Homework 1 to remind yourself what this dataset looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdf6165",
   "metadata": {},
   "source": [
    "### Problem 2.1: Setting up the data (5 points)\n",
    "\n",
    "First, we'll load our dataset and split it into a training set and a testing set. You are already given code that does this for you, and you only need to run it.\n",
    "\n",
    "- Use the scikit-learn class `StandardScaler` to standardize both the training and testing features. Remember that you should only fit the `StandardScaler` on the training data, and *not* the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a709e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features and labels for the MNIST dataset\n",
    "# This might take a minute to download the images.\n",
    "X, y = fetch_openml('mnist_784', as_frame=False, return_X_y=True)\n",
    "\n",
    "# Convert labels to integer data type\n",
    "y = y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aaf0360b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1, random_state=seed, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9f4099c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # make an instance of the StandardScaler Class\n",
    "scaler.fit(X_tr)\n",
    "X_tr = scaler.transform(X_tr)\n",
    "X_te = scaler.transform(X_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade9f85",
   "metadata": {},
   "source": [
    "### Problem 2.2: Varying the amount of training data (20 points)\n",
    "One reason that neural networks have become popular in recent years is that, for many problems, we now have access to very large datasets. Since neural networks are very flexible models, they are often able to take advantage of these large datasets in order to achieve high levels of accuracy. In this problem, you will vary the amount of training data available to a neural network and see what effect this has on the model's performance.\n",
    "\n",
    "In this problem, you should use the following settings for your network:\n",
    "- A single hidden layer with $64$ hidden nodes\n",
    "- Use the ReLU activation function\n",
    "- Train the network using stochastic gradient descent (SGD) and a learning rate of $0.001$\n",
    "- Use a batch size of 256\n",
    "- **Make sure to set `random_state=seed`.**\n",
    "\n",
    "Your task is to implement the following:\n",
    "- Train an MLP model (with the above hyperparameter settings) using the first `n_tr` feature vectors in `X_tr`, where `n_tr = [100, 1000, 5000, 10000, 20000, 50000, 63000]`. You should use the `MLPClassifier` class from scikit-learn in your implementation.\n",
    "- Train a logistic regression classifier (with the default settings in sklearn) using the first `n_tr` feature vectors in `X_tr`, where `n_tr = [100, 1000, 5000, 10000, 20000, 50000, 63000]` .You should use the `LogisticRegression` class from scikit-learn in your implementation. **Make sure to use the argument `random_state=seed` for reproducibility.**\n",
    "- Create a plot of the training error and testing error for both the logistic regression and MLP models as a function of the number of training data points. Be sure to include an x-label, y-label, and legend in your plot. Use a log-scale on the x-axis. Give a short (one or two sentences) description of what you see in your plot.\n",
    "\n",
    "Note that training a neural network with a lot of data can be a slow process. Hence, you should be careful to implement your code such that it runs in a reasonable amount of time. One recommendation is to test your code using only a small subset of the given `n_tr` values, and only run your code with all of the `n_tr` values given once you are certain your code is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47254d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d5cea1e",
   "metadata": {},
   "source": [
    "---\n",
    "### Problem 2.3: Learning Curves (10 points)\n",
    "\n",
    "One hyperparameter that can have a significant effect on the performance of your model is the learning rate, which controls the step size in (stochastic) gradient descent. In this problem you will vary the learning rate to see what effect this has on how quickly training converges as well as the effect on the performance of your model.\n",
    "\n",
    "In this problem, you should use the following settings for your network:\n",
    "- A single hidden layer with $64$ hidden nodes\n",
    "- Use the ReLU activation function\n",
    "- Train the network using stochastic gradient descent (SGD)\n",
    "- Set `n_iter_no_change=100` and `max_iter=100`. This ensures that all of your networks in this problem will train for 100 epochs (an *epoch* is one full pass over the training data).\n",
    "- Use a batch size of 256\n",
    "- **Make sure to set `random_state=seed`.**\n",
    "\n",
    "Your task is to:\n",
    "- Train a neural network with the above settings, but vary the learning rate in `lr = [0.0005, 0.001, 0.005, 0.01]`.\n",
    "- Create a plot showing the loss on the training set as a function of the training epoch (i.e. the x-axis corresponds to training iterations) for each learning rate above. You should have a single plot with four curves. Make sure to include an x-label, a y-label, and a legend in your plot. (Hint: `MLPClassifier` has an attribute `loss_curve_` that you likely find useful.)\n",
    "- Include a short description of what you see in your plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef4264",
   "metadata": {},
   "source": [
    "**Important: To make your code run faster, you should train all of your networks in this problem on only the first 10,000 images of `X_tr`**. In the following cell, you are provided a few lines of code that will create a small training set (with the first 10,000 images in `X_tr`) and a validation set (with the second 10,000 images in `X_tr`). You will use the validation later in Problem 2.4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919ce2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation sets from the second 10k images in X_tr\n",
    "X_val = X_tr[10000:20000]\n",
    "y_val = y_tr[10000:20000]\n",
    "\n",
    "# Create a smaller training set with the first 10k images in X_tr\n",
    "X_tr = X_tr[:10000]\n",
    "y_tr = y_tr[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ff6c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a0c7d5ea",
   "metadata": {},
   "source": [
    "### Problem 2.4: Tuning a Neural Network (30 points)\n",
    "\n",
    "As you saw in Problem 2.2, there are many hyperparameters of a neural network that can possibly be tuned in order to try to maximize the accuracy of your model. For the final problem of this assignment, it is your job to tune these hyperparameters.\n",
    "\n",
    "For example, some hyperparameters you might choose to tune are:\n",
    "- Learning rate\n",
    "- Depth/width\n",
    "- Regularization strength\n",
    "- Activation functions\n",
    "- Batch size\n",
    "- etc.\n",
    "\n",
    "To do this, you should train a network on the training data `X_tr` and evaluate its performance on the validation set `X_val` -- your goal is to achieve the highest possible accuracy on `X_val` by changing the network hyperparameters. **Important: To make your code run faster, you should train all of your networks in this problem on only the first 10,000 images of `X_tr`**. This was already set up for you in Problem 2.3.\n",
    "\n",
    "To receive full credit for this problem, you will need to tune your network hyperparameters until you achieve an error rate smaller than 5% on the validation data. However, tuning neural networks can be a difficult task, and you may not be able to achieve this target error rate. Hence, you will receive most of the credit for this problem as long as you train at least ten different neural networks with different settings of the hyperparameters.\n",
    "\n",
    "In your answer, include a table listing the different hyperparameters that you tried, along with the resulting accuracy on the training and validation sets `X_tr` and `X_val`. Indicate which of these hyperparameter settings you would choose for your final model, and report the accuracy of this final model on the testing set `X_te`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca4eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d083f0a8",
   "metadata": {
    "id": "4a052765"
   },
   "source": [
    "---\n",
    "### Statement of Collaboration (5 points)\n",
    "\n",
    "It is **mandatory** to include a Statement of Collaboration in each submission, with respect to the guidelines below. Include the names of everyone involved in the discussions (especially in-person ones), and what was discussed. If you did not collaborate with anyone, you should write something like \"I completed this assignment without any collaboration.\"\n",
    "\n",
    "All students are required to follow the academic honesty guidelines posted on the course website. For\n",
    "programming assignments, in particular, I encourage the students to organize (perhaps using EdD) to\n",
    "discuss the task descriptions, requirements, bugs in my code, and the relevant technical content before they start\n",
    "working on it. However, you should not discuss the specific solutions, and, as a guiding principle, you are not\n",
    "allowed to take anything written or drawn away from these discussions (i.e. no photographs of the blackboard,\n",
    "written notes, referring to EdD, etc.). Especially after you have started working on the assignment, try\n",
    "to restrict the discussion to EdD as much as possible, so that there is no doubt as to the extent of your\n",
    "collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f45f23",
   "metadata": {},
   "source": [
    "<font color = blue> I did not work with anybody else for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289233ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
